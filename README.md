# Project 1a Data Modeling with PostgreSQL
Author: Yimeng Wang \
Version: Python 3

## Table of Contents
1. [Goal](README.md#goal)
2. [Data](README.md#data)
3. [Database Schema](README.md#database-schema)
4. [Repo directory structure](README.md#repo-directory-structure)
5. [How to Run](README.md#how-to-run)

## Goal
Given two data sets - JSON logs on user activity and JSON metadata on music
library in a music streaming app, create a database schema and ETL pipeline
to optimize queries on users' song play analysis.

## Data
### Song Dataset
The first dataset is a subset of real data from the Million Song Dataset. 
Each file is in JSON format and contains metadata about a song and the artist 
of that song.
```bash
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", \
"artist_latitude": null,  "artist_longitude": null, \
"artist_location": "", "artist_name": "Line Renaud", \
"song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", \
"duration": 152.92036, "year": 0}
```
### Log Dataset
The second dataset consists of log files in JSON format generated by this event
simulator based on the songs in the dataset above. These simulate activity logs
from a music streaming app based on specified configurations.
```bash
{"artist":null,"auth":"Logged In", \
"firstName":"Walter","gender":"M", \
"itemInSession":0,"lastName":"Frye", \
"length":null,"level":"free", \
"location":"San Francisco-Oakland-Hayward, CA","method":"GET", \
"page":"Home","registration":1540919166796.0, \
"sessionId":38,"song":null,"status":200,"ts":1541105830796, \
"userAgent":"\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) \
AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 \
Safari\/537.36\"","userId":"39"}
```

## Database Schema
_Star Schema: one fact table surrounded by several dimension tables._ \
The details of each table are below. I designed in this way because it provides
flexibility for querying songs users are listening to since fact table can be
joined with one or more dimension tables for filtering. For example, we can join
users table with songplays table to see which songs paid female users listened
to.
### Fact Table
_songplays: records in log data associated with song plays_
 
|songplay_id|start_time|user_id|level  |song_id|artist_id|session_id|location|user_agent|
|-----------|----------|-------|-------|-------|---------|----------|--------|----------|
|SERIAL     |TIMESTAMP |INT    |VARCHAR|VARCHAR|VARCHAR  |INT       |VARCHAR |TEXT      |
### Dimension Tables
_users: users in the app_

|user_id|first_name|last_name|gender |level  |
|-------|----------|---------|-------|-------|
|VARCHAR|VARCHAR   |VARCHAR  |CHAR(1)|VARCHAR|

_songs: songs in music database_

|song_id|title  |artist_id|year|duration|
|-------|-------|---------|----|--------|
|VARCHAR|VARCHAR|VARCHAR  |INT |NUMERIC |

_artists: artists in music database_

|artist_id|name   |location|latitude|longitude|
|---------|-------|--------|--------|---------|
|VARCHAR  |VARCHAR|VARCHAR |NUMERIC |NUMERIC  |

_time: timestamps of records in songplays broken down into specific units_

|start_time|hour|day|week|month|year|weekday|
|----------|----|---|----|-----|----|-------|
|TIMESTAMP |INT |INT|INT |INT  |INT |INT    |

## Repo Directory Structure
|-- **README.md** \
|-- **etl.ipynb** reads and processes a single file from song_data and log_data \
|-- **etl.py** reads and processes all the files and load into tables \
|-- **sql_queries.py** contains all the sql queries \
|-- **create_tables.py** drops and creates your tables \
|-- **test.ipynb** let you check your database \
|-- **data** directory of JSON files \
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-- **song_data** \
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-- **log_data** 
    
## How to Run
You will not be able to run test.ipynb, etl.ipynb, or etl.py until you have 
run create_tables.py at least once to create the sparkifydb database, 
which these other files connect to.